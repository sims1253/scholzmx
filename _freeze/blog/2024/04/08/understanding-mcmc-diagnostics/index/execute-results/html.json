{
  "hash": "f84d1f5038ae5bdab71e64aab54c863c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Understanding MCMC Diagnostics: A Practical Guide\"\ndate: \"2024-04-08\"\ncategories: [Tutorial, Bayesian Statistics, MCMC]\ntags: [\"MCMC\", \"diagnostics\", \"Stan\", \"convergence\", \"R-hat\"]\ndescription: \"A comprehensive guide to diagnosing MCMC convergence issues and what to do when things go wrong.\"\n---\n\nMarkov Chain Monte Carlo (MCMC) methods are powerful tools for Bayesian inference, but they come with a catch: you need to verify that your chains have converged to the target distribution. In this tutorial, I'll walk you through the essential diagnostics and what to do when things go wrong.\n\n## Why MCMC Diagnostics Matter\n\nMCMC algorithms generate samples from complex posterior distributions, but there's no guarantee that your samples actually represent the distribution you're interested in. Poor convergence can lead to:\n\n- Biased parameter estimates\n- Incorrect uncertainty quantification\n- Invalid inferences and predictions\n\nThink of MCMC diagnostics as your early warning system—they tell you when your results might be unreliable.\n\n## Essential Diagnostics\n\n### 1. R-hat (Potential Scale Reduction Factor)\n\nR-hat compares the between-chain variance to the within-chain variance. Values close to 1.0 indicate good convergence.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rstan)\nlibrary(bayesplot)\n\n# Fit a simple model\nmodel_code <- \"\n  data {\n    int<lower=0> N;\n    vector[N] y;\n  }\n  parameters {\n    real mu;\n    real<lower=0> sigma;\n  }\n  model {\n    mu ~ normal(0, 10);\n    sigma ~ exponential(1);\n    y ~ normal(mu, sigma);\n  }\n\"\n\n# Simulate some data\nset.seed(123)\ny <- rnorm(100, 5, 2)\n\n# Fit the model\nfit <- stan(model_code = model_code, \n            data = list(N = length(y), y = y),\n            chains = 4, iter = 2000)\n\n# Check R-hat\nprint(fit, pars = c(\"mu\", \"sigma\"))\n```\n:::\n\n\n**Interpretation:**\n- R-hat < 1.01: Excellent convergence\n- 1.01 < R-hat < 1.05: Good convergence\n- R-hat > 1.05: Potential convergence issues\n\n### 2. Effective Sample Size (ESS)\n\nESS tells you how many independent samples your chains provide after accounting for autocorrelation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract samples and calculate ESS\nsamples <- extract(fit, permuted = FALSE)\ness <- summary(fit)$summary[, \"n_eff\"]\nprint(ess)\n\n# Rule of thumb: ESS > 100 per chain for reliable inference\n# ESS > 400 total for tail quantiles\n```\n:::\n\n\n### 3. Trace Plots\n\nVisual inspection of trace plots shows whether chains are mixing well.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(bayesplot)\n\n# Extract posterior samples\nposterior <- as.array(fit)\n\n# Create trace plots\nmcmc_trace(posterior, pars = c(\"mu\", \"sigma\"))\n```\n:::\n\n\n**Good trace plots look like:**\n- \"Fuzzy caterpillars\" - chains exploring the parameter space\n- Multiple chains overlapping completely\n- No systematic trends or patterns\n\n**Bad trace plots show:**\n- Chains stuck in different regions\n- Systematic trends or drift\n- Clear separation between chains\n\n### 4. Autocorrelation\n\nHigh autocorrelation reduces the effective sample size.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot autocorrelation\nmcmc_acf(posterior, pars = c(\"mu\", \"sigma\"))\n\n# Check autocorrelation at different lags\nacf_values <- summary(fit)$summary[, \"Rhat\"]\n```\n:::\n\n\n### 5. Divergent Transitions (Stan-specific)\n\nDivergent transitions indicate that the sampler couldn't accurately explore the posterior.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check for divergent transitions\ndivergent <- get_divergent_iterations(fit)\nprint(paste(\"Number of divergent transitions:\", sum(divergent)))\n\n# Plot divergent transitions\nmcmc_parcoord(posterior, np = nuts_params(fit))\n```\n:::\n\n\n## Common Problems and Solutions\n\n### Problem 1: High R-hat Values\n\n**Symptoms:**\n- R-hat > 1.05\n- Chains haven't converged to same distribution\n\n**Solutions:**\n1. **Run more iterations**:\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- stan(model_code = model_code, \n            data = data_list,\n            chains = 4, iter = 4000, warmup = 2000)\n```\n:::\n\n\n2. **Check for multimodality**:\n\n::: {.cell}\n\n```{.r .cell-code}\n# Look for multiple modes in marginal distributions\nmcmc_hist(posterior, pars = c(\"mu\", \"sigma\"))\n```\n:::\n\n\n3. **Improve parameterization**:\n\n::: {.cell}\n\n```{.r .cell-code}\n# Instead of estimating sigma directly, estimate log(sigma)\n# This often improves sampling efficiency\n```\n:::\n\n\n### Problem 2: Low Effective Sample Size\n\n**Symptoms:**\n- ESS < 100 per chain\n- High autocorrelation\n\n**Solutions:**\n1. **Increase adapt_delta**:\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- stan(model_code = model_code, \n            data = data_list,\n            control = list(adapt_delta = 0.95))\n```\n:::\n\n\n2. **Reparameterize the model**:\n\n::: {.cell}\n\n```{.r .cell-code}\n# Use non-centered parameterization for hierarchical models\n# Instead of: theta ~ normal(mu, sigma)\n# Use: theta_raw ~ normal(0, 1); theta = mu + sigma * theta_raw\n```\n:::\n\n\n### Problem 3: Divergent Transitions\n\n**Symptoms:**\n- Warning messages about divergent transitions\n- Biased estimates in problematic regions\n\n**Solutions:**\n1. **Increase adapt_delta**:\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- stan(model_code = model_code, \n            data = data_list,\n            control = list(adapt_delta = 0.99))\n```\n:::\n\n\n2. **Increase max_treedepth**:\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- stan(model_code = model_code, \n            data = data_list,\n            control = list(max_treedepth = 12))\n```\n:::\n\n\n3. **Reparameterize problematic parts**:\n\n::: {.cell}\n\n```{.r .cell-code}\n# Use stronger priors to regularize the model\n# Transform parameters to unconstrained space\n```\n:::\n\n\n## A Systematic Diagnostic Workflow\n\nHere's my recommended workflow for checking MCMC diagnostics:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. Basic convergence check\ncheck_convergence <- function(fit) {\n  summary_stats <- summary(fit)$summary\n  \n  # Check R-hat\n  max_rhat <- max(summary_stats[, \"Rhat\"], na.rm = TRUE)\n  cat(\"Maximum R-hat:\", max_rhat, \"\\n\")\n  \n  # Check effective sample size\n  min_ess <- min(summary_stats[, \"n_eff\"], na.rm = TRUE)\n  cat(\"Minimum ESS:\", min_ess, \"\\n\")\n  \n  # Check divergent transitions\n  divergent <- get_divergent_iterations(fit)\n  cat(\"Divergent transitions:\", sum(divergent), \"\\n\")\n  \n  # Overall assessment\n  if (max_rhat < 1.01 & min_ess > 100 & sum(divergent) == 0) {\n    cat(\"✓ Diagnostics look good!\\n\")\n  } else {\n    cat(\"⚠ Potential issues detected\\n\")\n  }\n}\n\n# 2. Visual diagnostics\nplot_diagnostics <- function(fit, pars) {\n  posterior <- as.array(fit)\n  \n  # Trace plots\n  p1 <- mcmc_trace(posterior, pars = pars)\n  \n  # Autocorrelation\n  p2 <- mcmc_acf(posterior, pars = pars)\n  \n  # Marginal distributions\n  p3 <- mcmc_hist(posterior, pars = pars)\n  \n  # Pairs plot for correlations\n  p4 <- mcmc_pairs(posterior, pars = pars)\n  \n  return(list(trace = p1, acf = p2, hist = p3, pairs = p4))\n}\n\n# Use the functions\ncheck_convergence(fit)\nplots <- plot_diagnostics(fit, c(\"mu\", \"sigma\"))\n```\n:::\n\n\n## Advanced Diagnostics\n\n### Energy Diagnostics\n\nFor Hamiltonian Monte Carlo (like Stan's NUTS):\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check energy diagnostics\nmcmc_nuts_energy(nuts_params(fit))\n```\n:::\n\n\n### Rank Plots\n\nA newer diagnostic that's robust to many issues:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Rank plots\nmcmc_rank_overlay(posterior, pars = c(\"mu\", \"sigma\"))\n```\n:::\n\n\n## When All Else Fails\n\nIf diagnostics continue to indicate problems:\n\n1. **Simplify the model**: Remove complexity until you achieve convergence\n2. **Simulate fake data**: Test your model on data where you know the true parameters\n3. **Try different software**: Sometimes a different sampler works better\n4. **Consult the literature**: Look for similar models and their parameterizations\n\n## Conclusion\n\nMCMC diagnostics are your friend—they prevent you from making inferences based on unreliable samples. The key principles are:\n\n1. **Always check diagnostics** before interpreting results\n2. **Use multiple diagnostics** together, not just one\n3. **Understand what each diagnostic tells you** about potential problems\n4. **Don't ignore warnings** from your MCMC software\n5. **When in doubt, run longer** (but fix underlying issues first)\n\nRemember: it's better to have a simple model that converges than a complex model that doesn't.\n\n---\n\n*Have you encountered tricky MCMC convergence issues? What diagnostic tools have you found most helpful? I'd love to hear about your experiences with challenging models.*",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}