---
title: "Kumaraswamy custom brms family"
description: "Creating a custom brms family for the Kumaraswamy distribution with median parametrization"
date: 2022-03-14
categories: [Statistics, R]
tags: ["brms", "Bayesian", "custom family", "Kumaraswamy"]
author: "Maximilian Scholz"
execute:
  echo: true
  eval: true
  warning: false
  message: false
format:
  md:
    variant: gfm
    preserve-yaml: true
---

The Kumaraswamy distribution is a flexible continuous probability distribution defined on the interval [0,1], similar to the Beta distribution but with a simpler cumulative distribution function. In this post, I'll show how to create a custom brms family for this distribution using a median parametrization.

```{r}
#| label: setup
#| include: false

library(brms)
library(tidyverse)
library(bayesplot)
library(patchwork)

theme_set(theme_minimal())
```

## The Kumaraswamy Distribution

The Kumaraswamy distribution has two shape parameters α and β, with probability density function:

f(x; α, β) = αβx^(α-1)(1-x^α)^(β-1)

The cumulative distribution function has a closed form:

F(x; α, β) = 1 - (1-x^α)^β

## Median Parametrization

Instead of using the shape parameters directly, I'll parametrize the distribution using the median and a concentration parameter. This often leads to more interpretable priors.

```{r}
#| label: median-parametrization

# Convert median + concentration to shape parameters
median_to_shape <- function(median, conc) {
  # Solve for alpha given median
  alpha <- log(2) / log(1 - median^(1/conc))
  return(list(alpha = alpha, beta = conc))
}

# Convert shape parameters to median + concentration  
shape_to_median <- function(alpha, beta) {
  median <- (1 - 2^(-1/beta))^(1/alpha)
  return(list(median = median, conc = beta))
}

# Test the conversion
params <- median_to_shape(median = 0.3, conc = 2)
print(params)

check <- shape_to_median(params$alpha, params$beta)
print(check)
```

## Density and Random Generation Functions

```{r}
#| label: distribution-functions

# Density function (median parametrization)
dkumar_med <- function(x, median, conc, log = FALSE) {
  # Convert to shape parameters
  params <- median_to_shape(median, conc)
  alpha <- params$alpha
  beta <- params$beta
  
  # Calculate density
  if (log) {
    log(alpha) + log(beta) + (alpha - 1) * log(x) + (beta - 1) * log(1 - x^alpha)
  } else {
    alpha * beta * x^(alpha - 1) * (1 - x^alpha)^(beta - 1)
  }
}

# Random generation (median parametrization)
rkumar_med <- function(n, median, conc) {
  # Convert to shape parameters
  params <- median_to_shape(median, conc)
  alpha <- params$alpha
  beta <- params$beta
  
  # Generate using inverse CDF
  u <- runif(n)
  (1 - (1 - u)^(1/beta))^(1/alpha)
}

# Test the functions
set.seed(123)
samples <- rkumar_med(1000, median = 0.3, conc = 2)

# Visualize
tibble(x = samples) %>%
  ggplot(aes(x = x)) +
  geom_histogram(aes(y = ..density..), bins = 30, alpha = 0.7) +
  stat_function(fun = dkumar_med, args = list(median = 0.3, conc = 2), 
                color = "red", size = 1) +
  labs(title = "Kumaraswamy Distribution (median = 0.3, conc = 2)",
       x = "x", y = "Density")
```

## Custom brms Family

Now let's create the custom brms family:

```{r}
#| label: custom-family

# Log-likelihood function for brms
log_lik_kumaraswamy_med <- function(i, prep) {
  mu <- brms::get_dpar(prep, "mu", i = i)
  conc <- brms::get_dpar(prep, "conc", i = i) 
  y <- prep$data$Y[i]
  dkumar_med(y, mu, conc, log = TRUE)
}

# Posterior prediction function
posterior_predict_kumaraswamy_med <- function(i, prep, ...) {
  mu <- brms::get_dpar(prep, "mu", i = i)
  conc <- brms::get_dpar(prep, "conc", i = i)
  rkumar_med(prep$ndraws, mu, conc)
}

# Create the custom family
kumaraswamy_med <- brms::custom_family(
  "kumaraswamy_med",
  dpars = c("mu", "conc"),
  links = c("logit", "log"),
  lb = c(0, 0),
  ub = c(1, NA),
  type = "real",
  vars = "vreal1[n]"
)

# Add the functions to the family
stanvars_kumaraswamy <- brms::stanvar(scode = "
  real kumaraswamy_med_lpdf(real y, real mu, real conc) {
    real alpha = log(2) / log(1 - mu^(1/conc));
    real beta = conc;
    return log(alpha) + log(beta) + (alpha - 1) * log(y) + (beta - 1) * log(1 - y^alpha);
  }
", block = "functions")
```

## Fitting a Model

Let's simulate some data and fit a model:

```{r}
#| label: model-fitting

# Simulate data
set.seed(456)
n <- 200
x <- rnorm(n)
true_median <- plogis(-0.5 + 0.8 * x)  # logit link for median
true_conc <- 3

y <- map_dbl(true_median, ~rkumar_med(1, .x, true_conc))

sim_data <- tibble(x = x, y = y)

# Visualize the simulated data
sim_data %>%
  ggplot(aes(x = x, y = y)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "loess") +
  labs(title = "Simulated Data",
       x = "Predictor", y = "Response")
```

```{r}
#| label: brms-model
#| results: hide

# Fit the model
model <- brm(
  bf(y ~ x, conc ~ 1), 
  data = sim_data,
  family = kumaraswamy_med,
  stanvars = stanvars_kumaraswamy,
  prior = c(
    prior(normal(0, 1), class = Intercept),
    prior(normal(0, 0.5), class = b),
    prior(gamma(2, 1), class = Intercept, dpar = conc)
  ),
  chains = 4,
  iter = 2000,
  cores = 4,
  refresh = 0
)
```

```{r}
#| label: model-results

# Check the results
print(model)

# Posterior predictive checks
pp_check(model, ndraws = 50) +
  labs(title = "Posterior Predictive Check")
```

## Comparison with Beta Distribution

Let's compare our Kumaraswamy model with a Beta regression:

```{r}
#| label: comparison
#| results: hide

# Fit Beta model for comparison
beta_model <- brm(
  bf(y ~ x), 
  data = sim_data,
  family = Beta(),
  chains = 4,
  iter = 2000,
  cores = 4,
  refresh = 0
)
```

```{r}
#| label: model-comparison

# Compare fits
loo_kumar <- loo(model)
loo_beta <- loo(beta_model)

loo_compare(loo_kumar, loo_beta)

# Plot predicted medians
newdata <- tibble(x = seq(-2, 2, length.out = 100))

# Kumaraswamy predictions
pred_kumar <- fitted(model, newdata = newdata, summary = FALSE)
kumar_summary <- apply(pred_kumar, 2, quantile, c(0.025, 0.5, 0.975))

# Beta predictions  
pred_beta <- fitted(beta_model, newdata = newdata, summary = FALSE)
beta_summary <- apply(pred_beta, 2, quantile, c(0.025, 0.5, 0.975))

# Combine and plot
comparison_data <- tibble(
  x = rep(newdata$x, 2),
  median = c(kumar_summary[2,], beta_summary[2,]),
  lower = c(kumar_summary[1,], beta_summary[1,]),
  upper = c(kumar_summary[3,], beta_summary[3,]),
  model = rep(c("Kumaraswamy", "Beta"), each = 100)
)

comparison_data %>%
  ggplot(aes(x = x, y = median, color = model, fill = model)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) +
  geom_line() +
  geom_point(data = sim_data, aes(x = x, y = y), 
             color = "black", alpha = 0.4, inherit.aes = FALSE) +
  labs(title = "Model Comparison: Kumaraswamy vs Beta",
       x = "Predictor", y = "Response")
```

## Conclusion

The Kumaraswamy distribution provides a flexible alternative to the Beta distribution for modeling data on [0,1]. Key advantages include:

1. **Closed-form CDF**: Makes some calculations easier
2. **Interpretable parametrization**: Using median + concentration
3. **Similar flexibility**: Can model various shapes like Beta

The custom brms family allows us to easily incorporate this distribution into Bayesian regression models. The median parametrization makes it easier to specify informative priors and interpret results.

For data that naturally lives on [0,1], consider trying both Beta and Kumaraswamy distributions to see which fits better!

## References

- Kumaraswamy, P. (1980). A generalized probability density function for double-bounded random processes. Journal of Hydrology, 46(1-2), 79-88.
- Jones, M. C. (2009). Kumaraswamy's distribution: A beta-type distribution with some tractability advantages. Statistical Methodology, 6(1), 70-81.